"""
æœåŠ¡æä¾›å•†å·¥å‚ - æ ¹æ®é…ç½®åˆ›å»ºå¯¹åº”çš„ STT/LLM/TTS æœåŠ¡å®ä¾‹
"""
import os
import logging
from typing import Optional, Callable, Awaitable
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)


# ==================== STT æœåŠ¡æŠ½è±¡åŸºç±» ====================

class BaseSTTProvider(ABC):
    """STT æœåŠ¡æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    async def transcribe(self, audio_bytes: bytes) -> str:
        """å°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡æœ¬"""
        pass


class DeepgramSTTProvider(BaseSTTProvider):
    """Deepgram STT æœåŠ¡"""
    
    def __init__(self, api_key: str, model: str = "nova-2", language: str = "zh-CN"):
        self.api_key = api_key
        self.model = model
        self.language = language
        self._client = None
        
    async def _get_client(self):
        if self._client is None:
            try:
                from deepgram import DeepgramClient, PrerecordedOptions
                self._client = DeepgramClient(self.api_key)
            except ImportError:
                raise ImportError("è¯·å®‰è£… deepgram-sdk: pip install deepgram-sdk")
        return self._client
    
    async def transcribe(self, audio_bytes: bytes) -> str:
        """ä½¿ç”¨ Deepgram è¿›è¡Œè¯­éŸ³è¯†åˆ«"""
        try:
            from deepgram import PrerecordedOptions
            
            client = await self._get_client()
            
            options = PrerecordedOptions(
                model=self.model,
                language=self.language,
                smart_format=True,
            )
            
            response = await client.listen.asyncrest.v("1").transcribe_file(
                {"buffer": audio_bytes, "mimetype": "audio/raw"},
                options
            )
            
            transcript = response.results.channels[0].alternatives[0].transcript
            logger.info(f"ğŸ“ è½¬å½•: {transcript}")
            return transcript
            
        except Exception as e:
            logger.error(f"Deepgram è½¬å½•é”™è¯¯: {e}")
            return ""


class OpenAIWhisperSTTProvider(BaseSTTProvider):
    """OpenAI Whisper STT æœåŠ¡"""
    
    def __init__(self, api_key: str, base_url: str = "https://api.openai.com/v1"):
        self.api_key = api_key
        self.base_url = base_url
        self._client = None
        
    async def _get_client(self):
        if self._client is None:
            try:
                from openai import AsyncOpenAI
                self._client = AsyncOpenAI(api_key=self.api_key, base_url=self.base_url)
            except ImportError:
                raise ImportError("è¯·å®‰è£… openai: pip install openai")
        return self._client
    
    async def transcribe(self, audio_bytes: bytes) -> str:
        """ä½¿ç”¨ OpenAI Whisper è¿›è¡Œè¯­éŸ³è¯†åˆ«"""
        try:
            import io
            import wave
            
            client = await self._get_client()
            
            # å°† PCM è½¬æ¢ä¸º WAV æ ¼å¼
            wav_buffer = io.BytesIO()
            with wave.open(wav_buffer, 'wb') as wav_file:
                wav_file.setnchannels(1)
                wav_file.setsampwidth(2)
                wav_file.setframerate(16000)
                wav_file.writeframes(audio_bytes)
            wav_buffer.seek(0)
            wav_buffer.name = "audio.wav"
            
            response = await client.audio.transcriptions.create(
                model="whisper-1",
                file=wav_buffer,
                language="zh"
            )
            
            transcript = response.text
            logger.info(f"ğŸ“ è½¬å½•: {transcript}")
            return transcript
            
        except Exception as e:
            logger.error(f"OpenAI Whisper è½¬å½•é”™è¯¯: {e}")
            return ""


class LocalWhisperSTTProvider(BaseSTTProvider):
    """æœ¬åœ° Whisper STT æœåŠ¡"""
    
    def __init__(self, model: str = "base"):
        self.model_name = model
        self._model = None
        
    def _load_model(self):
        if self._model is None:
            try:
                import whisper  # type: ignore
                logger.info(f"åŠ è½½æœ¬åœ° Whisper æ¨¡å‹: {self.model_name}")
                self._model = whisper.load_model(self.model_name)
            except ImportError:
                raise ImportError("è¯·å®‰è£… openai-whisper: pip install openai-whisper")
        return self._model
    
    async def transcribe(self, audio_bytes: bytes) -> str:
        """ä½¿ç”¨æœ¬åœ° Whisper è¿›è¡Œè¯­éŸ³è¯†åˆ«"""
        try:
            import numpy as np
            import tempfile
            import wave
            import asyncio
            
            model = self._load_model()
            
            # å°†éŸ³é¢‘å†™å…¥ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
                with wave.open(f.name, 'wb') as wav_file:
                    wav_file.setnchannels(1)
                    wav_file.setsampwidth(2)
                    wav_file.setframerate(16000)
                    wav_file.writeframes(audio_bytes)
                temp_path = f.name
            
            # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œ Whisper
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                None, 
                lambda: model.transcribe(temp_path, language="zh")
            )
            
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            import os
            os.unlink(temp_path)
            
            transcript = result["text"].strip()
            logger.info(f"ğŸ“ è½¬å½•: {transcript}")
            return transcript
            
        except Exception as e:
            logger.error(f"æœ¬åœ° Whisper è½¬å½•é”™è¯¯: {e}")
            return ""


# ==================== LLM æœåŠ¡æŠ½è±¡åŸºç±» ====================

class BaseLLMProvider(ABC):
    """LLM æœåŠ¡æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    async def generate_stream(
        self, 
        prompt: str, 
        system_prompt: str,
        on_chunk: Callable[[str], Awaitable[None]]
    ) -> str:
        """æµå¼ç”Ÿæˆæ–‡æœ¬å“åº”"""
        pass


class OpenAILLMProvider(BaseLLMProvider):
    """OpenAI LLM æœåŠ¡"""
    
    def __init__(
        self, 
        api_key: str, 
        model: str = "gpt-4o",
        base_url: str = "https://api.openai.com/v1",
        temperature: float = 0.7,
        max_tokens: int = 4096
    ):
        self.api_key = api_key
        self.model = model
        self.base_url = base_url
        self.temperature = temperature
        self.max_tokens = max_tokens
        self._client = None
        self._conversation_history = []
        
    async def _get_client(self):
        if self._client is None:
            try:
                from openai import AsyncOpenAI
                self._client = AsyncOpenAI(api_key=self.api_key, base_url=self.base_url)
            except ImportError:
                raise ImportError("è¯·å®‰è£… openai: pip install openai")
        return self._client
    
    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self._conversation_history = []
    
    async def generate_stream(
        self, 
        prompt: str, 
        system_prompt: str,
        on_chunk: Callable[[str], Awaitable[None]]
    ) -> str:
        """æµå¼ç”Ÿæˆ OpenAI å“åº”"""
        try:
            client = await self._get_client()
            
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [{"role": "system", "content": system_prompt}]
            messages.extend(self._conversation_history)
            messages.append({"role": "user", "content": prompt})
            
            # æ·»åŠ åˆ°å†å²
            self._conversation_history.append({"role": "user", "content": prompt})
            
            full_response = ""
            
            stream = await client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=self.temperature,
                max_tokens=self.max_tokens,
                stream=True
            )
            
            async for chunk in stream:
                if chunk.choices[0].delta.content:
                    text = chunk.choices[0].delta.content
                    full_response += text
                    await on_chunk(text)
            
            # æ·»åŠ åŠ©æ‰‹å“åº”åˆ°å†å²
            self._conversation_history.append({"role": "assistant", "content": full_response})
            
            logger.info(f"ğŸ’¬ LLM: {full_response[:80]}...")
            return full_response
            
        except Exception as e:
            logger.error(f"OpenAI ç”Ÿæˆé”™è¯¯: {e}")
            return f"æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜: {str(e)}"


class OllamaLLMProvider(BaseLLMProvider):
    """Ollama LLM æœåŠ¡"""
    
    def __init__(
        self, 
        base_url: str = "http://localhost:11434",
        model: str = "llama3:8b",
        temperature: float = 0.7
    ):
        self.base_url = base_url
        self.model = model
        self.temperature = temperature
        self._conversation_history = []
        
    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self._conversation_history = []
    
    async def generate_stream(
        self, 
        prompt: str, 
        system_prompt: str,
        on_chunk: Callable[[str], Awaitable[None]]
    ) -> str:
        """æµå¼ç”Ÿæˆ Ollama å“åº”"""
        try:
            import aiohttp
            import json
            
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [{"role": "system", "content": system_prompt}]
            messages.extend(self._conversation_history)
            messages.append({"role": "user", "content": prompt})
            
            # æ·»åŠ åˆ°å†å²
            self._conversation_history.append({"role": "user", "content": prompt})
            
            full_response = ""
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.base_url}/api/chat",
                    json={
                        "model": self.model,
                        "messages": messages,
                        "stream": True,
                        "options": {"temperature": self.temperature}
                    }
                ) as response:
                    async for line in response.content:
                        if line:
                            try:
                                data = json.loads(line.decode())
                                if "message" in data and "content" in data["message"]:
                                    text = data["message"]["content"]
                                    full_response += text
                                    await on_chunk(text)
                            except json.JSONDecodeError:
                                continue
            
            # æ·»åŠ åŠ©æ‰‹å“åº”åˆ°å†å²
            self._conversation_history.append({"role": "assistant", "content": full_response})
            
            logger.info(f"ğŸ’¬ LLM: {full_response[:80]}...")
            return full_response
            
        except Exception as e:
            logger.error(f"Ollama ç”Ÿæˆé”™è¯¯: {e}")
            return f"æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜: {str(e)}"


# ==================== TTS æœåŠ¡æŠ½è±¡åŸºç±» ====================

class BaseTTSProvider(ABC):
    """TTS æœåŠ¡æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    async def synthesize_stream(
        self, 
        text: str,
        on_audio_chunk: Callable[[bytes], Awaitable[None]]
    ) -> bytes:
        """æµå¼åˆæˆè¯­éŸ³"""
        pass


class ElevenLabsTTSProvider(BaseTTSProvider):
    """ElevenLabs TTS æœåŠ¡"""
    
    def __init__(
        self, 
        api_key: str, 
        voice_id: str = "21m00Tcm4TlvDq8ikWAM",
        model: str = "eleven_monolingual_v1"
    ):
        self.api_key = api_key
        self.voice_id = voice_id
        self.model = model
        
    async def synthesize_stream(
        self, 
        text: str,
        on_audio_chunk: Callable[[bytes], Awaitable[None]]
    ) -> bytes:
        """æµå¼åˆæˆ ElevenLabs è¯­éŸ³"""
        try:
            import aiohttp
            
            url = f"https://api.elevenlabs.io/v1/text-to-speech/{self.voice_id}/stream"
            headers = {
                "Accept": "audio/mpeg",
                "Content-Type": "application/json",
                "xi-api-key": self.api_key
            }
            data = {
                "text": text,
                "model_id": self.model,
                "voice_settings": {
                    "stability": 0.5,
                    "similarity_boost": 0.75
                }
            }
            
            full_audio = b""
            
            async with aiohttp.ClientSession() as session:
                async with session.post(url, headers=headers, json=data) as response:
                    if response.status == 200:
                        async for chunk in response.content.iter_chunked(4096):
                            full_audio += chunk
                            await on_audio_chunk(chunk)
                    else:
                        error = await response.text()
                        logger.error(f"ElevenLabs TTS é”™è¯¯: {error}")
            
            logger.debug(f"ğŸ”Š TTS å®Œæˆ: {len(full_audio)} bytes")
            return full_audio
            
        except Exception as e:
            logger.error(f"ElevenLabs TTS é”™è¯¯: {e}")
            return b""


class EdgeTTSProvider(BaseTTSProvider):
    """Edge TTS æœåŠ¡ (å…è´¹)"""
    
    def __init__(self, voice: str = "zh-CN-XiaoxiaoNeural"):
        self.voice = voice
        
    async def synthesize_stream(
        self, 
        text: str,
        on_audio_chunk: Callable[[bytes], Awaitable[None]]
    ) -> bytes:
        """æµå¼åˆæˆ Edge TTS è¯­éŸ³"""
        try:
            import edge_tts
            import io
            
            communicate = edge_tts.Communicate(text, self.voice)
            
            full_audio = b""
            
            async for chunk in communicate.stream():
                if chunk["type"] == "audio":
                    audio_data = chunk["data"]
                    full_audio += audio_data
                    await on_audio_chunk(audio_data)
            
            logger.debug(f"ğŸ”Š TTS å®Œæˆ: {len(full_audio)} bytes")
            return full_audio
            
        except ImportError:
            raise ImportError("è¯·å®‰è£… edge-tts: pip install edge-tts")
        except Exception as e:
            logger.error(f"Edge TTS é”™è¯¯: {e}")
            return b""


class OpenAITTSProvider(BaseTTSProvider):
    """OpenAI TTS æœåŠ¡"""
    
    def __init__(
        self, 
        api_key: str, 
        voice: str = "alloy",
        model: str = "tts-1",
        base_url: str = "https://api.openai.com/v1"
    ):
        self.api_key = api_key
        self.voice = voice
        self.model = model
        self.base_url = base_url
        self._client = None
        
    async def _get_client(self):
        if self._client is None:
            try:
                from openai import AsyncOpenAI
                self._client = AsyncOpenAI(api_key=self.api_key, base_url=self.base_url)
            except ImportError:
                raise ImportError("è¯·å®‰è£… openai: pip install openai")
        return self._client
    
    async def synthesize_stream(
        self, 
        text: str,
        on_audio_chunk: Callable[[bytes], Awaitable[None]]
    ) -> bytes:
        """æµå¼åˆæˆ OpenAI TTS è¯­éŸ³"""
        try:
            client = await self._get_client()
            
            response = await client.audio.speech.create(
                model=self.model,
                voice=self.voice,
                input=text,
                response_format="pcm"  # 16-bit PCM
            )
            
            full_audio = response.content
            
            # åˆ†å—å‘é€
            chunk_size = 4096
            for i in range(0, len(full_audio), chunk_size):
                chunk = full_audio[i:i+chunk_size]
                await on_audio_chunk(chunk)
            
            logger.debug(f"ğŸ”Š TTS å®Œæˆ: {len(full_audio)} bytes")
            return full_audio
            
        except Exception as e:
            logger.error(f"OpenAI TTS é”™è¯¯: {e}")
            return b""


# ==================== æœåŠ¡å·¥å‚ ====================

class ServiceFactory:
    """æœåŠ¡å·¥å‚ - æ ¹æ®é…ç½®åˆ›å»ºæœåŠ¡å®ä¾‹"""
    
    @staticmethod
    def create_stt_provider(provider: str, **kwargs) -> BaseSTTProvider:
        """åˆ›å»º STT æœåŠ¡æä¾›å•†"""
        providers = {
            "deepgram": lambda: DeepgramSTTProvider(
                api_key=kwargs.get("api_key", os.getenv("DEEPGRAM_API_KEY", "")),
                model=kwargs.get("model", os.getenv("DEEPGRAM_MODEL", "nova-2")),
                language=kwargs.get("language", os.getenv("DEEPGRAM_LANGUAGE", "zh-CN"))
            ),
            "openai_whisper": lambda: OpenAIWhisperSTTProvider(
                api_key=kwargs.get("api_key", os.getenv("OPENAI_API_KEY", "")),
                base_url=kwargs.get("base_url", os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1"))
            ),
            "local_whisper": lambda: LocalWhisperSTTProvider(
                model=kwargs.get("model", os.getenv("WHISPER_MODEL", "base"))
            )
        }
        
        if provider not in providers:
            raise ValueError(f"æœªçŸ¥çš„ STT æœåŠ¡æä¾›å•†: {provider}. å¯é€‰: {list(providers.keys())}")
        
        logger.info(f"åˆ›å»º STT æœåŠ¡: {provider}")
        return providers[provider]()
    
    @staticmethod
    def create_llm_provider(provider: str, **kwargs) -> BaseLLMProvider:
        """åˆ›å»º LLM æœåŠ¡æä¾›å•†"""
        providers = {
            "openai": lambda: OpenAILLMProvider(
                api_key=kwargs.get("api_key", os.getenv("OPENAI_API_KEY", "")),
                model=kwargs.get("model", os.getenv("OPENAI_MODEL", "gpt-4o")),
                base_url=kwargs.get("base_url", os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")),
                temperature=float(kwargs.get("temperature", os.getenv("LLM_TEMPERATURE", "0.7"))),
                max_tokens=int(kwargs.get("max_tokens", os.getenv("LLM_MAX_TOKENS", "4096")))
            ),
            "ollama": lambda: OllamaLLMProvider(
                base_url=kwargs.get("base_url", os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")),
                model=kwargs.get("model", os.getenv("OLLAMA_MODEL", "llama3:8b")),
                temperature=float(kwargs.get("temperature", os.getenv("LLM_TEMPERATURE", "0.7")))
            ),
            "siliconflow": lambda: OpenAILLMProvider(
                api_key=kwargs.get("api_key", os.getenv("SILICONFLOW_API_KEY", "")),
                model=kwargs.get("model", os.getenv("SILICONFLOW_MODEL", "Qwen/Qwen2.5-7B-Instruct")),
                base_url=kwargs.get("base_url", os.getenv("SILICONFLOW_BASE_URL", "https://api.siliconflow.cn/v1")),
                temperature=float(kwargs.get("temperature", os.getenv("LLM_TEMPERATURE", "0.7"))),
                max_tokens=int(kwargs.get("max_tokens", os.getenv("LLM_MAX_TOKENS", "4096")))
            )
        }
        
        if provider not in providers:
            raise ValueError(f"æœªçŸ¥çš„ LLM æœåŠ¡æä¾›å•†: {provider}. å¯é€‰: {list(providers.keys())}")
        
        logger.info(f"åˆ›å»º LLM æœåŠ¡: {provider}")
        return providers[provider]()
    
    @staticmethod
    def create_tts_provider(provider: str, **kwargs) -> BaseTTSProvider:
        """åˆ›å»º TTS æœåŠ¡æä¾›å•†"""
        providers = {
            "elevenlabs": lambda: ElevenLabsTTSProvider(
                api_key=kwargs.get("api_key", os.getenv("ELEVENLABS_API_KEY", "")),
                voice_id=kwargs.get("voice_id", os.getenv("ELEVENLABS_VOICE_ID", "21m00Tcm4TlvDq8ikWAM")),
                model=kwargs.get("model", os.getenv("ELEVENLABS_MODEL", "eleven_monolingual_v1"))
            ),
            "edge_tts": lambda: EdgeTTSProvider(
                voice=kwargs.get("voice", os.getenv("EDGE_TTS_VOICE", "zh-CN-XiaoxiaoNeural"))
            ),
            "openai_tts": lambda: OpenAITTSProvider(
                api_key=kwargs.get("api_key", os.getenv("OPENAI_API_KEY", "")),
                voice=kwargs.get("voice", os.getenv("OPENAI_TTS_VOICE", "alloy")),
                model=kwargs.get("model", os.getenv("OPENAI_TTS_MODEL", "tts-1")),
                base_url=kwargs.get("base_url", os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1"))
            )
        }
        
        if provider not in providers:
            raise ValueError(f"æœªçŸ¥çš„ TTS æœåŠ¡æä¾›å•†: {provider}. å¯é€‰: {list(providers.keys())}")
        
        logger.info(f"åˆ›å»º TTS æœåŠ¡: {provider}")
        return providers[provider]()
