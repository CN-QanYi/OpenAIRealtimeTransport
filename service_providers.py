"""
æœåŠ¡æä¾›å•†å·¥å‚ - æ ¹æ®é…ç½®åˆ›å»ºå¯¹åº”çš„ STT/LLM/TTS æœåŠ¡å®ä¾‹
"""
import os
import asyncio
import logging
from typing import Optional, Callable, Awaitable
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)


# ==================== STT æœåŠ¡æŠ½è±¡åŸºç±» ====================

class BaseSTTProvider(ABC):
    """STT æœåŠ¡æŠ½è±¡åŸºç±»"""
    
    # é»˜è®¤é‡‡æ ·ç‡ï¼ˆä¸ protocol.py AudioFormat ä¿æŒä¸€è‡´ï¼‰
    DEFAULT_SAMPLE_RATE: int = 24000
    
    @abstractmethod
    async def transcribe(self, audio_bytes: bytes, sample_rate: int = DEFAULT_SAMPLE_RATE) -> str:
        """å°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡æœ¬
        
        Args:
            audio_bytes: åŸå§‹ PCM éŸ³é¢‘æ•°æ®
            sample_rate: éŸ³é¢‘é‡‡æ ·ç‡ (Hz)ï¼Œé»˜è®¤ 24000
        
        Returns:
            è½¬å½•çš„æ–‡æœ¬
        """
        pass


class DeepgramSTTProvider(BaseSTTProvider):
    """Deepgram STT æœåŠ¡"""
    
    def __init__(self, api_key: str, model: str = "nova-2", language: str = "zh-CN"):
        self.api_key = api_key
        self.model = model
        self.language = language
        self._client = None
        
    async def _get_client(self):
        if self._client is None:
            try:
                # deepgram-sdk>=5 ä½¿ç”¨å…³é”®å­—å‚æ•°åˆå§‹åŒ–ï¼›å¹¶æä¾› AsyncDeepgramClient ç”¨äºå¼‚æ­¥è°ƒç”¨
                from deepgram import AsyncDeepgramClient
                self._client = AsyncDeepgramClient(api_key=self.api_key)
            except ImportError as err:
                raise ImportError("è¯·å®‰è£… deepgram-sdk: pip install deepgram-sdk") from err
        return self._client
    
    async def transcribe(self, audio_bytes: bytes, sample_rate: int = BaseSTTProvider.DEFAULT_SAMPLE_RATE) -> str:
        """ä½¿ç”¨ Deepgram è¿›è¡Œè¯­éŸ³è¯†åˆ«"""
        try:
            client = await self._get_client()

            if not audio_bytes:
                return ""

            # é˜²å¾¡æ€§å¤„ç†ï¼šPCM16 å¿…é¡» 2 å­—èŠ‚å¯¹é½
            if len(audio_bytes) % 2 != 0:
                logger.warning("Deepgram: audio_bytes é•¿åº¦é 2 å­—èŠ‚å¯¹é½ï¼Œå·²æˆªæ–­æœ€å 1 å­—èŠ‚")
                audio_bytes = audio_bytes[:-1]

            # Deepgram å¯¹ raw PCM çš„å‚æ•°ç»„åˆéå¸¸æ•æ„Ÿï¼ˆé‡‡æ ·ç‡/ç¼–ç /å¤´ä¿¡æ¯ä¸åŒ¹é…ä¼šæŠ¥ 400ï¼‰ã€‚
            # è¿™é‡Œç»Ÿä¸€å°è£…ä¸º WAV å†ä¸Šä¼ ï¼Œè®©æœåŠ¡ç«¯æŒ‰ WAV å¤´è§£æã€‚
            import io
            import wave
            wav_buffer = io.BytesIO()
            with wave.open(wav_buffer, "wb") as wav_file:
                wav_file.setnchannels(1)
                wav_file.setsampwidth(2)
                wav_file.setframerate(int(sample_rate))
                wav_file.writeframes(audio_bytes)
            wav_bytes = wav_buffer.getvalue()

            from deepgram.core.request_options import RequestOptions
            request_options = RequestOptions(
                additional_headers={
                    "Content-Type": "audio/wav",
                }
            )

            response = await client.listen.v1.media.transcribe_file(
                request=wav_bytes,
                model=self.model,
                language=self.language,
                smart_format=True,
                request_options=request_options,
            )
            
            transcript = response.results.channels[0].alternatives[0].transcript
            logger.info(f"ğŸ“ è½¬å½•: {transcript}")
            return transcript
            
        except Exception as e:
            logger.error(f"Deepgram è½¬å½•é”™è¯¯: {e}")
            return ""


class OpenAIWhisperSTTProvider(BaseSTTProvider):
    """OpenAI Whisper STT æœåŠ¡"""
    
    def __init__(self, api_key: str, base_url: str = "https://api.openai.com/v1"):
        self.api_key = api_key
        self.base_url = base_url
        self._client = None
        
    async def _get_client(self):
        if self._client is None:
            try:
                from openai import AsyncOpenAI
                self._client = AsyncOpenAI(api_key=self.api_key, base_url=self.base_url)
            except ImportError as err:
                raise ImportError("è¯·å®‰è£… openai: pip install openai") from err
        return self._client
    
    async def transcribe(self, audio_bytes: bytes, sample_rate: int = BaseSTTProvider.DEFAULT_SAMPLE_RATE) -> str:
        """ä½¿ç”¨ OpenAI Whisper è¿›è¡Œè¯­éŸ³è¯†åˆ«"""
        try:
            import io
            import wave
            
            # éªŒè¯ sample_rate
            if not isinstance(sample_rate, int) or sample_rate <= 0:
                logger.warning(f"sample_rate æ— æ•ˆ ({sample_rate})ï¼Œä½¿ç”¨é»˜è®¤å€¼ {self.DEFAULT_SAMPLE_RATE}")
                sample_rate = self.DEFAULT_SAMPLE_RATE
            
            client = await self._get_client()
            
            # å°† PCM è½¬æ¢ä¸º WAV æ ¼å¼
            wav_buffer = io.BytesIO()
            with wave.open(wav_buffer, 'wb') as wav_file:
                wav_file.setnchannels(1)
                wav_file.setsampwidth(2)
                wav_file.setframerate(sample_rate)
                wav_file.writeframes(audio_bytes)
            wav_buffer.seek(0)
            wav_buffer.name = "audio.wav"
            
            response = await client.audio.transcriptions.create(
                model="whisper-1",
                file=wav_buffer,
                language="zh"
            )
            
            transcript = response.text
            logger.info(f"ğŸ“ è½¬å½•: {transcript}")
            return transcript
            
        except Exception as e:
            logger.error(f"OpenAI Whisper è½¬å½•é”™è¯¯: {e}")
            return ""


class LocalWhisperSTTProvider(BaseSTTProvider):
    """æœ¬åœ° Whisper STT æœåŠ¡"""
    
    def __init__(self, model: str = "base"):
        self.model_name = model
        self._model = None
        
    def _load_model(self):
        if self._model is None:
            try:
                import whisper  # type: ignore
                logger.info(f"åŠ è½½æœ¬åœ° Whisper æ¨¡å‹: {self.model_name}")
                self._model = whisper.load_model(self.model_name)
            except ImportError:
                raise ImportError("è¯·å®‰è£… openai-whisper: pip install openai-whisper")
        return self._model
    
    async def transcribe(self, audio_bytes: bytes, sample_rate: int = BaseSTTProvider.DEFAULT_SAMPLE_RATE) -> str:
        """ä½¿ç”¨æœ¬åœ° Whisper è¿›è¡Œè¯­éŸ³è¯†åˆ«"""
        import os
        import tempfile
        import wave
        
        # éªŒè¯ sample_rate
        if not isinstance(sample_rate, int) or sample_rate <= 0:
            logger.warning(f"sample_rate æ— æ•ˆ ({sample_rate})ï¼Œä½¿ç”¨é»˜è®¤å€¼ {self.DEFAULT_SAMPLE_RATE}")
            sample_rate = self.DEFAULT_SAMPLE_RATE
        
        temp_path: str | None = None
        try:
            model = self._load_model()
            
            # å°†éŸ³é¢‘å†™å…¥ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
                temp_path = f.name
                with wave.open(temp_path, 'wb') as wav_file:
                    wav_file.setnchannels(1)
                    wav_file.setsampwidth(2)
                    wav_file.setframerate(sample_rate)
                    wav_file.writeframes(audio_bytes)
            
            # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œ Whisperï¼ˆä½¿ç”¨ asyncio.get_running_loop æ›¿ä»£å·²å¼ƒç”¨çš„ get_event_loopï¼‰
            loop = asyncio.get_running_loop()
            result = await loop.run_in_executor(
                None, 
                lambda: model.transcribe(temp_path, language="zh")
            )
            
            transcript = result["text"].strip()
            logger.info(f"ğŸ“ è½¬å½•: {transcript}")
            return transcript
            
        except Exception as e:
            logger.error(f"æœ¬åœ° Whisper è½¬å½•é”™è¯¯: {e}")
            return ""
        finally:
            # ç¡®ä¿ä¸´æ—¶æ–‡ä»¶å§‹ç»ˆè¢«åˆ é™¤
            if temp_path is not None:
                try:
                    os.unlink(temp_path)
                except OSError as unlink_err:
                    logger.warning(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥ ({temp_path}): {unlink_err}")


# ==================== LLM æœåŠ¡æŠ½è±¡åŸºç±» ====================

class BaseLLMProvider(ABC):
    """LLM æœåŠ¡æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    async def generate_stream(
        self, 
        prompt: str, 
        system_prompt: str,
        on_chunk: Callable[[str], Awaitable[None]]
    ) -> str:
        """æµå¼ç”Ÿæˆæ–‡æœ¬å“åº”"""
        pass


class OpenAILLMProvider(BaseLLMProvider):
    """OpenAI LLM æœåŠ¡"""
    
    def __init__(
        self, 
        api_key: str, 
        model: str = "gpt-4o",
        base_url: str = "https://api.openai.com/v1",
        temperature: float = 0.7,
        max_tokens: int = 4096
    ):
        self.api_key = api_key
        self.model = model
        self.base_url = base_url
        self.temperature = temperature
        self.max_tokens = max_tokens
        self._client = None
        self._conversation_history = []
        
    async def _get_client(self):
        if self._client is None:
            try:
                from openai import AsyncOpenAI
                self._client = AsyncOpenAI(api_key=self.api_key, base_url=self.base_url)
            except ImportError:
                raise ImportError("è¯·å®‰è£… openai: pip install openai")
        return self._client
    
    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self._conversation_history = []
    
    async def generate_stream(
        self, 
        prompt: str, 
        system_prompt: str,
        on_chunk: Callable[[str], Awaitable[None]]
    ) -> str:
        """æµå¼ç”Ÿæˆ OpenAI å“åº”"""
        try:
            client = await self._get_client()
            
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [{"role": "system", "content": system_prompt}]
            messages.extend(self._conversation_history)
            messages.append({"role": "user", "content": prompt})
            
            # æ·»åŠ åˆ°å†å²
            self._conversation_history.append({"role": "user", "content": prompt})
            
            full_response = ""
            
            stream = await client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=self.temperature,
                max_tokens=self.max_tokens,
                stream=True
            )
            
            async for chunk in stream:
                if chunk.choices[0].delta.content:
                    text = chunk.choices[0].delta.content
                    full_response += text
                    await on_chunk(text)
            
            # æ·»åŠ åŠ©æ‰‹å“åº”åˆ°å†å²
            self._conversation_history.append({"role": "assistant", "content": full_response})
            
            logger.info(f"ğŸ’¬ LLM: {full_response[:80]}...")
            return full_response
            
        except Exception as e:
            logger.error(f"OpenAI ç”Ÿæˆé”™è¯¯: {e}")
            return f"æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜: {str(e)}"


class OllamaLLMProvider(BaseLLMProvider):
    """Ollama LLM æœåŠ¡"""
    
    def __init__(
        self, 
        base_url: str = "http://localhost:11434",
        model: str = "llama3:8b",
        temperature: float = 0.7
    ):
        self.base_url = base_url
        self.model = model
        self.temperature = temperature
        self._conversation_history = []
        
    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self._conversation_history = []
    
    async def generate_stream(
        self, 
        prompt: str, 
        system_prompt: str,
        on_chunk: Callable[[str], Awaitable[None]]
    ) -> str:
        """æµå¼ç”Ÿæˆ Ollama å“åº”"""
        try:
            import aiohttp
            import json
            
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [{"role": "system", "content": system_prompt}]
            messages.extend(self._conversation_history)
            messages.append({"role": "user", "content": prompt})
            
            # æ·»åŠ åˆ°å†å²
            self._conversation_history.append({"role": "user", "content": prompt})
            
            full_response = ""
            
            # é…ç½®è¶…æ—¶ï¼šè¿æ¥è¶…æ—¶10ç§’ï¼Œæ€»è¶…æ—¶300ç§’ï¼ˆ5åˆ†é’Ÿï¼Œé€‚åˆæµå¼å“åº”ï¼‰
            timeout = aiohttp.ClientTimeout(total=300, connect=10)
            try:
                async with aiohttp.ClientSession(timeout=timeout) as session:
                    async with session.post(
                        f"{self.base_url}/api/chat",
                        json={
                            "model": self.model,
                            "messages": messages,
                            "stream": True,
                            "options": {"temperature": self.temperature}
                        }
                    ) as response:
                        async for line in response.content:
                            if line:
                                try:
                                    data = json.loads(line.decode())
                                    if "message" in data and "content" in data["message"]:
                                        text = data["message"]["content"]
                                        full_response += text
                                        await on_chunk(text)
                                except json.JSONDecodeError:
                                    continue
            except asyncio.TimeoutError:
                logger.error(f"Ollama è¯·æ±‚è¶…æ—¶ (base_url: {self.base_url})")
                return "æŠ±æ­‰ï¼Œè¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•ã€‚"
            except aiohttp.ClientError as client_err:
                logger.error(f"Ollama è¿æ¥é”™è¯¯: {client_err}")
                return f"æŠ±æ­‰ï¼Œæ— æ³•è¿æ¥åˆ° Ollama æœåŠ¡: {str(client_err)}"
            
            # æ·»åŠ åŠ©æ‰‹å“åº”åˆ°å†å²
            self._conversation_history.append({"role": "assistant", "content": full_response})
            
            logger.info(f"ğŸ’¬ LLM: {full_response[:80]}...")
            return full_response
            
        except Exception as e:
            logger.error(f"Ollama ç”Ÿæˆé”™è¯¯: {e}")
            return f"æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜: {str(e)}"


# ==================== TTS æœåŠ¡æŠ½è±¡åŸºç±» ====================

class BaseTTSProvider(ABC):
    """TTS æœåŠ¡æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    async def synthesize_stream(
        self, 
        text: str,
        on_audio_chunk: Callable[[bytes], Awaitable[None]]
    ) -> bytes:
        """æµå¼åˆæˆè¯­éŸ³"""
        pass


class ElevenLabsTTSProvider(BaseTTSProvider):
    """ElevenLabs TTS æœåŠ¡"""
    
    def __init__(
        self, 
        api_key: str, 
        voice_id: str = "21m00Tcm4TlvDq8ikWAM",
        model: str = "eleven_monolingual_v1"
    ):
        self.api_key = api_key
        self.voice_id = voice_id
        self.model = model
        
    async def synthesize_stream(
        self, 
        text: str,
        on_audio_chunk: Callable[[bytes], Awaitable[None]]
    ) -> bytes:
        """æµå¼åˆæˆ ElevenLabs è¯­éŸ³"""
        try:
            import aiohttp
            
            url = f"https://api.elevenlabs.io/v1/text-to-speech/{self.voice_id}/stream"
            headers = {
                "Accept": "audio/mpeg",
                "Content-Type": "application/json",
                "xi-api-key": self.api_key
            }
            data = {
                "text": text,
                "model_id": self.model,
                "voice_settings": {
                    "stability": 0.5,
                    "similarity_boost": 0.75
                }
            }
            
            full_audio = b""
            
            # é…ç½®è¶…æ—¶ï¼šè¿æ¥è¶…æ—¶10ç§’ï¼Œæ€»è¶…æ—¶60ç§’
            timeout = aiohttp.ClientTimeout(total=60, connect=10)
            try:
                async with aiohttp.ClientSession(timeout=timeout) as session:
                    async with session.post(url, headers=headers, json=data) as response:
                        if response.status == 200:
                            async for chunk in response.content.iter_chunked(4096):
                                full_audio += chunk
                                await on_audio_chunk(chunk)
                        else:
                            error = await response.text()
                            logger.error(f"ElevenLabs TTS é”™è¯¯: {error}")
            except asyncio.TimeoutError:
                logger.error(f"ElevenLabs TTS è¯·æ±‚è¶…æ—¶ (voice_id: {self.voice_id})")
                return b""
            except aiohttp.ClientError as client_err:
                logger.error(f"ElevenLabs TTS è¿æ¥é”™è¯¯: {client_err}")
                return b""
            
            logger.debug(f"ğŸ”Š TTS å®Œæˆ: {len(full_audio)} bytes")
            return full_audio
            
        except Exception as e:
            logger.error(f"ElevenLabs TTS é”™è¯¯: {e}")
            return b""


class EdgeTTSProvider(BaseTTSProvider):
    """Edge TTS æœåŠ¡ (å…è´¹)"""
    
    def __init__(self, voice: str = "zh-CN-XiaoxiaoNeural"):
        self.voice = voice
        
    async def synthesize_stream(
        self, 
        text: str,
        on_audio_chunk: Callable[[bytes], Awaitable[None]]
    ) -> bytes:
        """æµå¼åˆæˆ Edge TTS è¯­éŸ³"""
        try:
            import edge_tts

            text = (text or "").strip()
            if not text:
                logger.info("Edge TTS: æ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡åˆæˆ")
                return b""

            # å¯é€‰ï¼šé€šè¿‡ç¯å¢ƒå˜é‡é…ç½®ä»£ç†ä¸è¶…æ—¶ï¼ˆé€‚åˆå›½å†…ç½‘ç»œç¯å¢ƒï¼‰
            proxy = os.getenv("EDGE_TTS_PROXY") or None
            try:
                connect_timeout = int(os.getenv("EDGE_TTS_CONNECT_TIMEOUT", "10"))
            except ValueError:
                connect_timeout = 10
            try:
                receive_timeout = int(os.getenv("EDGE_TTS_RECEIVE_TIMEOUT", "60"))
            except ValueError:
                receive_timeout = 60

            # å¤±è´¥æ—¶è‡ªåŠ¨å›é€€ voiceï¼ˆå¸¸è§åŸå› ï¼švoice åä¸æ”¯æŒ / æœåŠ¡ç«¯æ— éŸ³é¢‘è¿”å›ï¼‰
            candidate_voices = [
                self.voice,
                "zh-CN-XiaoxiaoNeural",
                "zh-CN-YunxiNeural",
                "zh-CN-YunjianNeural",
            ]
            seen = set()
            voices_to_try = [v for v in candidate_voices if v and not (v in seen or seen.add(v))]
            
            last_error: Exception | None = None
            for voice in voices_to_try:
                try:
                    communicate = edge_tts.Communicate(
                        text,
                        voice,
                        proxy=proxy,
                        connect_timeout=connect_timeout,
                        receive_timeout=receive_timeout,
                    )

                    full_audio = b""
                    async for chunk in communicate.stream():
                        if chunk["type"] == "audio":
                            audio_data = chunk["data"]
                            full_audio += audio_data
                            await on_audio_chunk(audio_data)

                    if full_audio:
                        logger.debug(f"ğŸ”Š TTS å®Œæˆ (voice={voice}): {len(full_audio)} bytes")
                        return full_audio

                    # stream ç»“æŸä½†æ²¡æœ‰ä»»ä½•éŸ³é¢‘å—
                    last_error = RuntimeError("No audio was received")
                    logger.warning(f"Edge TTS æ— éŸ³é¢‘è¿”å›ï¼Œå°è¯•åˆ‡æ¢ voice: {voice}")

                except Exception as e:
                    last_error = e
                    msg = str(e)
                    # å¯¹å¯æ¢å¤é”™è¯¯å°è¯•ä¸‹ä¸€ä¸ª voice
                    if "No audio was received" in msg or "voice" in msg.lower():
                        logger.warning(f"Edge TTS å¤±è´¥ (voice={voice}): {e}ï¼Œå°è¯•ä¸‹ä¸€ä¸ª voice")
                        continue
                    # å…¶ä»–é”™è¯¯ï¼ˆç½‘ç»œ/åè®®ï¼‰ä¹Ÿå°è¯•ä¸€æ¬¡å›é€€ï¼Œä½†é¿å…åˆ·å±
                    logger.warning(f"Edge TTS å¤±è´¥ (voice={voice}): {e}")
                    continue

            logger.error(f"Edge TTS é”™è¯¯: {last_error}")
            return b""
            
        except ImportError:
            raise ImportError("è¯·å®‰è£… edge-tts: pip install edge-tts")


class OpenAITTSProvider(BaseTTSProvider):
    """OpenAI TTS æœåŠ¡"""
    
    def __init__(
        self, 
        api_key: str, 
        voice: str = "alloy",
        model: str = "tts-1",
        base_url: str = "https://api.openai.com/v1"
    ):
        self.api_key = api_key
        self.voice = voice
        self.model = model
        self.base_url = base_url
        self._client = None
        
    async def _get_client(self):
        if self._client is None:
            try:
                from openai import AsyncOpenAI
                self._client = AsyncOpenAI(api_key=self.api_key, base_url=self.base_url)
            except ImportError as err:
                raise ImportError("è¯·å®‰è£… openai: pip install openai") from err
        return self._client
    
    async def synthesize_stream(
        self, 
        text: str,
        on_audio_chunk: Callable[[bytes], Awaitable[None]]
    ) -> bytes:
        """æµå¼åˆæˆ OpenAI TTS è¯­éŸ³"""
        try:
            client = await self._get_client()

            text = (text or "").strip()
            if not text:
                logger.info("OpenAI TTS: æ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡åˆæˆ")
                return b""
            
            response = await client.audio.speech.create(
                model=self.model,
                voice=self.voice,
                input=text,
                response_format="pcm"  # 16-bit PCM
            )
            
            full_audio = response.content
            if not full_audio:
                return b""

            # PCM16 å¿…é¡» 2 å­—èŠ‚å¯¹é½
            if len(full_audio) % 2 != 0:
                full_audio = full_audio[:-1]

            # ç»Ÿä¸€åˆ°å†…éƒ¨ 16kHzï¼Œé¿å… Transport é‡é‡‡æ ·å‡è®¾ä¸å®é™…é‡‡æ ·ç‡ä¸ä¸€è‡´
            try:
                from audio_utils import resample_audio, SAMPLE_RATE as _CLIENT_SR, INTERNAL_SAMPLE_RATE as _INTERNAL_SR
                full_audio = resample_audio(full_audio, from_rate=_CLIENT_SR, to_rate=_INTERNAL_SR)
            except Exception as _e:
                logger.warning(f"OpenAI TTS: é‡é‡‡æ ·å¤±è´¥ï¼Œå°†ç›´æ¥å‘é€åŸå§‹éŸ³é¢‘: {_e}")
            
            # åˆ†å—å‘é€
            chunk_size = 4096
            for i in range(0, len(full_audio), chunk_size):
                chunk = full_audio[i:i+chunk_size]
                await on_audio_chunk(chunk)
            
            logger.debug(f"ğŸ”Š TTS å®Œæˆ: {len(full_audio)} bytes")
            return full_audio
            
        except Exception as e:
            logger.error(f"OpenAI TTS é”™è¯¯: {e}")
            return b""


# ==================== æœåŠ¡å·¥å‚ ====================

class ServiceFactory:
    """æœåŠ¡å·¥å‚ - æ ¹æ®é…ç½®åˆ›å»ºæœåŠ¡å®ä¾‹"""
    
    @staticmethod
    def create_stt_provider(provider: str, **kwargs) -> BaseSTTProvider:
        """åˆ›å»º STT æœåŠ¡æä¾›å•†"""
        providers = {
            "deepgram": lambda: DeepgramSTTProvider(
                api_key=kwargs.get("api_key", os.getenv("DEEPGRAM_API_KEY", "")),
                model=kwargs.get("model", os.getenv("DEEPGRAM_MODEL", "nova-2")),
                language=kwargs.get("language", os.getenv("DEEPGRAM_LANGUAGE", "zh-CN"))
            ),
            "openai_whisper": lambda: OpenAIWhisperSTTProvider(
                api_key=kwargs.get("api_key", os.getenv("OPENAI_API_KEY", "")),
                base_url=kwargs.get("base_url", os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1"))
            ),
            "local_whisper": lambda: LocalWhisperSTTProvider(
                model=kwargs.get("model", os.getenv("WHISPER_MODEL", "base"))
            )
        }
        
        if provider not in providers:
            raise ValueError(f"æœªçŸ¥çš„ STT æœåŠ¡æä¾›å•†: {provider}. å¯é€‰: {list(providers.keys())}")
        
        logger.info(f"åˆ›å»º STT æœåŠ¡: {provider}")
        return providers[provider]()
    
    @staticmethod
    def create_llm_provider(provider: str, **kwargs) -> BaseLLMProvider:
        """åˆ›å»º LLM æœåŠ¡æä¾›å•†"""
        providers = {
            "openai": lambda: OpenAILLMProvider(
                api_key=kwargs.get("api_key", os.getenv("OPENAI_API_KEY", "")),
                model=kwargs.get("model", os.getenv("OPENAI_MODEL", "gpt-4o")),
                base_url=kwargs.get("base_url", os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")),
                temperature=float(kwargs.get("temperature", os.getenv("LLM_TEMPERATURE", "0.7"))),
                max_tokens=int(kwargs.get("max_tokens", os.getenv("LLM_MAX_TOKENS", "4096")))
            ),
            "ollama": lambda: OllamaLLMProvider(
                base_url=kwargs.get("base_url", os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")),
                model=kwargs.get("model", os.getenv("OLLAMA_MODEL", "llama3:8b")),
                temperature=float(kwargs.get("temperature", os.getenv("LLM_TEMPERATURE", "0.7")))
            ),
            "siliconflow": lambda: OpenAILLMProvider(
                api_key=kwargs.get("api_key", os.getenv("SILICONFLOW_API_KEY", "")),
                model=kwargs.get("model", os.getenv("SILICONFLOW_MODEL", "Qwen/Qwen2.5-7B-Instruct")),
                base_url=kwargs.get("base_url", os.getenv("SILICONFLOW_BASE_URL", "https://api.siliconflow.cn/v1")),
                temperature=float(kwargs.get("temperature", os.getenv("LLM_TEMPERATURE", "0.7"))),
                max_tokens=int(kwargs.get("max_tokens", os.getenv("LLM_MAX_TOKENS", "4096")))
            )
        }
        
        if provider not in providers:
            raise ValueError(f"æœªçŸ¥çš„ LLM æœåŠ¡æä¾›å•†: {provider}. å¯é€‰: {list(providers.keys())}")
        
        logger.info(f"åˆ›å»º LLM æœåŠ¡: {provider}")
        return providers[provider]()
    
    @staticmethod
    def create_tts_provider(provider: str, **kwargs) -> BaseTTSProvider:
        """åˆ›å»º TTS æœåŠ¡æä¾›å•†"""
        providers = {
            "elevenlabs": lambda: ElevenLabsTTSProvider(
                api_key=kwargs.get("api_key", os.getenv("ELEVENLABS_API_KEY", "")),
                voice_id=kwargs.get("voice_id", os.getenv("ELEVENLABS_VOICE_ID", "21m00Tcm4TlvDq8ikWAM")),
                model=kwargs.get("model", os.getenv("ELEVENLABS_MODEL", "eleven_monolingual_v1"))
            ),
            "edge_tts": lambda: EdgeTTSProvider(
                voice=kwargs.get("voice", os.getenv("EDGE_TTS_VOICE", "zh-CN-XiaoxiaoNeural"))
            ),
            "openai_tts": lambda: OpenAITTSProvider(
                api_key=kwargs.get("api_key", os.getenv("OPENAI_API_KEY", "")),
                voice=kwargs.get("voice", os.getenv("OPENAI_TTS_VOICE", "alloy")),
                model=kwargs.get("model", os.getenv("OPENAI_TTS_MODEL", "tts-1")),
                base_url=kwargs.get("base_url", os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1"))
            )
        }
        
        if provider not in providers:
            raise ValueError(f"æœªçŸ¥çš„ TTS æœåŠ¡æä¾›å•†: {provider}. å¯é€‰: {list(providers.keys())}")
        
        logger.info(f"åˆ›å»º TTS æœåŠ¡: {provider}")
        return providers[provider]()
